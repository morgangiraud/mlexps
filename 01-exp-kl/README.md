# Experiment 01 - Kullback Leibler minimization
In this experiment, we check that minimizing the Kullback Leibler divergence indeed allows one to learn a disteribution when in the right conditions:
- Both distributions are from the same family
- Distributions defined on the same support
- Data spans the most of the support

## Hypothesis
The minimization of the Kullback Leibler divergence between 2 distributions which have the same support using data which spans most of the support leads to matched distributions.

## Result
Yes. It works.